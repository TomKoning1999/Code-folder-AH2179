{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe7ca76",
   "metadata": {},
   "source": [
    "# Assignment module 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35b454",
   "metadata": {},
   "source": [
    "This assignment covers sentiment analysis. The main goal is to train a model in Python that is able to predict the sentiment in a sentence. For this multiple combinations of vectorizers and models will be tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1edefd1",
   "metadata": {},
   "source": [
    "### Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862e91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746fd31",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3ed661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path of the dataset\n",
    "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_4_Text_classification/Pakistani%20Traffic%20sentiment%20Analysis.csv'\n",
    "\n",
    "# Load the data use the pandas\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696033ca",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7535b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2109 entries, 0 to 2108\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       2109 non-null   object\n",
      " 1   Sentiment  2109 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 33.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>1008</td>\n",
       "      <td>Traffic open at shahrah e faisal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1099</td>\n",
       "      <td>1079</td>\n",
       "      <td>Road is closed for traffic at star gate toward...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text                                                               \n",
       "          count unique                                                top freq\n",
       "Sentiment                                                                     \n",
       "0          1010   1008                   Traffic open at shahrah e faisal    2\n",
       "1          1099   1079  Road is closed for traffic at star gate toward...    3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "# Displaying the instances of each class\n",
    "df.groupby('Sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43257e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>Adayala road is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1079</td>\n",
       "      <td>1079</td>\n",
       "      <td>Traffic jam from parbat rd to nazim-ud-din rd ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text                                                               \n",
       "          count unique                                                top freq\n",
       "Sentiment                                                                     \n",
       "0          1008   1008                              Adayala road is clear    1\n",
       "1          1079   1079  Traffic jam from parbat rd to nazim-ud-din rd ...    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Displaying the instances of each class\n",
    "df.groupby('Sentiment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa4208",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f440373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model Vectorize  \\\n",
      "0       LogisticRegression       NaN   \n",
      "1       LogisticRegression       NaN   \n",
      "2       LogisticRegression       NaN   \n",
      "3     KNeighborsClassifier       NaN   \n",
      "4     KNeighborsClassifier       NaN   \n",
      "5     KNeighborsClassifier       NaN   \n",
      "6   RandomForestClassifier       NaN   \n",
      "7   RandomForestClassifier       NaN   \n",
      "8   RandomForestClassifier       NaN   \n",
      "9            XGBClassifier       NaN   \n",
      "10           XGBClassifier       NaN   \n",
      "11           XGBClassifier       NaN   \n",
      "12                     SVC       NaN   \n",
      "13                     SVC       NaN   \n",
      "14                     SVC       NaN   \n",
      "15             BernoulliNB       NaN   \n",
      "16             BernoulliNB       NaN   \n",
      "17             BernoulliNB       NaN   \n",
      "\n",
      "                                   Optimal parameters  \\\n",
      "0                                            {'C': 1}   \n",
      "1                                           {'C': 10}   \n",
      "2                                          {'C': 0.1}   \n",
      "3           {'n_neighbors': 7, 'weights': 'distance'}   \n",
      "4            {'n_neighbors': 9, 'weights': 'uniform'}   \n",
      "5           {'n_neighbors': 7, 'weights': 'distance'}   \n",
      "6   {'max_depth': None, 'min_samples_leaf': 1, 'mi...   \n",
      "7   {'max_depth': None, 'min_samples_leaf': 2, 'mi...   \n",
      "8   {'max_depth': 30, 'min_samples_leaf': 1, 'min_...   \n",
      "9   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
      "10  {'learning_rate': 0.2, 'max_depth': 5, 'n_esti...   \n",
      "11  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...   \n",
      "12                         {'C': 10, 'kernel': 'rbf'}   \n",
      "13                         {'C': 10, 'kernel': 'rbf'}   \n",
      "14                     {'C': 0.1, 'kernel': 'linear'}   \n",
      "15                  {'alpha': 1, 'force_alpha': True}   \n",
      "16                  {'alpha': 1, 'force_alpha': True}   \n",
      "17                  {'alpha': 1, 'force_alpha': True}   \n",
      "\n",
      "    Accuracy score training  Accuracy score test         Vectorizer  \n",
      "0                  0.950869             0.937799    CountVectorizer  \n",
      "1                  0.955667             0.952153  HashingVectorizer  \n",
      "2                  0.953270             0.956938    TfidfVectorizer  \n",
      "3                  0.931114             0.959330    CountVectorizer  \n",
      "4                  0.940089             0.954545  HashingVectorizer  \n",
      "5                  0.881362             0.930622    TfidfVectorizer  \n",
      "6                  0.959260             0.968900    CountVectorizer  \n",
      "7                  0.974237             0.971292  HashingVectorizer  \n",
      "8                  0.956865             0.968900    TfidfVectorizer  \n",
      "9                  0.956266             0.959330    CountVectorizer  \n",
      "10                 0.972441             0.973684  HashingVectorizer  \n",
      "11                 0.954475             0.964115    TfidfVectorizer  \n",
      "12                 0.955068             0.959330    CountVectorizer  \n",
      "13                 0.972444             0.971292  HashingVectorizer  \n",
      "14                 0.952074             0.954545    TfidfVectorizer  \n",
      "15                 0.949069             0.949761    CountVectorizer  \n",
      "16                 0.805877             0.834928  HashingVectorizer  \n",
      "17                 0.947271             0.944976    TfidfVectorizer  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n",
      "C:\\Users\\tomko\\AppData\\Local\\Temp\\ipykernel_49876\\3311241703.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params,\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"LogisticRegression\", \"KNeighborsClassifier\", \"RandomForestClassifier\", \"XGBClassifier\", \"SVC\", \"BernoulliNB\"]\n",
    "vectorizer_list = [\"CountVectorizer\", \"HashingVectorizer\", \"TfidfVectorizer\"]\n",
    "df_results = pd.DataFrame(columns = [\"Model\", \"Vectorize\", \"Optimal parameters\", \"Accuracy score training\", \"Accuracy score test\"])\n",
    "\n",
    "for i in model_list:\n",
    "    for j in vectorizer_list:\n",
    "        #Test all the possible vectorizers:\n",
    "        if j == \"CountVectorizer\":\n",
    "            vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english',min_df=20)\n",
    "        elif j == \"HashingVectorizer\":\n",
    "            vectorizer = HashingVectorizer(ngram_range=(1, 2), n_features=200)\n",
    "        elif j == \"TfidfVectorizer\":\n",
    "            vectorizer = TfidfVectorizer(min_df=20,norm='l2',smooth_idf=True,use_idf=True,ngram_range=(1, 1),stop_words='english')\n",
    "        else:\n",
    "            print(\"Error: Vectorizer not assigned correctly\")\n",
    "        \n",
    "        #Set the vectorizer and split the data in a train and test set:\n",
    "        x = vectorizer.fit_transform(df['Text'])\n",
    "        y = df['Sentiment']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=0)\n",
    "        \n",
    "        #Test all the possible model types:\n",
    "        if i == \"LogisticRegression\":\n",
    "            model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "            param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "        elif i == \"KNeighborsClassifier\":\n",
    "            model=KNeighborsClassifier()\n",
    "            param_grid = {'n_neighbors': [3, 5, 7, 9], \n",
    "                          'weights': ['uniform', 'distance']}\n",
    "        elif i == \"RandomForestClassifier\":\n",
    "            model = RandomForestClassifier(random_state=0)\n",
    "            param_grid = {'n_estimators': [100, 200, 300], \n",
    "                          'max_depth': [None, 10, 20, 30], \n",
    "                          'min_samples_split': [2, 5, 10], \n",
    "                          'min_samples_leaf': [1, 2, 4]}\n",
    "        elif i == \"XGBClassifier\":\n",
    "            model =  XGBClassifier()\n",
    "            param_grid = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "                          'n_estimators': [100, 200, 300],\n",
    "                          'max_depth': [3, 4, 5]}\n",
    "        elif i == \"SVC\":\n",
    "            model= SVC(probability=True)\n",
    "            param_grid = {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                          'C': [0.1, 1, 10]}\n",
    "        elif i == \"BernoulliNB\":\n",
    "            model=BernoulliNB()\n",
    "            param_grid = {'alpha': [0.1, 0.5, 1],\n",
    "                          'force_alpha': [True,False]}\n",
    "        else:\n",
    "            print(\"Error: Model not assigned correctly\")\n",
    "            \n",
    "        \n",
    "        #Perform gridsearch with 5 fold cross-validtion to maximize the accuracy for the model-vectorizer combination:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "        #Fit the model to the training set for each combination in the gridsearch:\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        #Find best parameters and corresponding accuracy score:\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        #Run the model-vectorizer combination on the test set for the best parameter combination\n",
    "        model = grid_search.best_estimator_\n",
    "        \n",
    "        \n",
    "        #Add the results to the results dataframe\n",
    "        df_results = df_results.append({\"Model\" : i, \"Vectorizer\" : j, \"Optimal parameters\" : best_params, \n",
    "                                        \"Accuracy score training\" : best_score, \n",
    "                                        \"Accuracy score test\" : accuracy_score(y_test,model.predict(x_test))}, \n",
    "                                       ignore_index = True)\n",
    "        \n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
