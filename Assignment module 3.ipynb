{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f136ef93",
   "metadata": {},
   "source": [
    "# Assignment task - Find the best classification model for the travel mode choices prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7d310",
   "metadata": {},
   "source": [
    "The goal of this assignment is to find the best classification model to predict travel mode choices. The dataset contains the cost, access time, travel time and service of multiple travel modes. In this assignment I will look at car, bus, train and air travel. In this assignment multiple types of classification models are compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1937c7",
   "metadata": {},
   "source": [
    "### Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fdbbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29102e77",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f354d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise-3%20mode%20choice%20model/modeChoiceData.csv'\n",
    "#data = pd.read_csv(url)\n",
    "\n",
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffaa711",
   "metadata": {},
   "source": [
    "### Train and test all combinations of encoders and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf1ae2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('one-hot encoding', 'LR', 6.666666666666667, '%')\n",
      "Progress:  ('one-hot encoding', 'KNN', 13.333333333333334, '%')\n",
      "Progress:  ('one-hot encoding', 'RF', 20.0, '%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('one-hot encoding', 'XGBoost', 26.666666666666668, '%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('one-hot encoding', 'SVM', 33.33333333333333, '%')\n",
      "Progress:  ('label encoding', 'LR', 40.0, '%')\n",
      "Progress:  ('label encoding', 'KNN', 46.666666666666664, '%')\n",
      "Progress:  ('label encoding', 'RF', 53.333333333333336, '%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('label encoding', 'XGBoost', 60.0, '%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('label encoding', 'SVM', 66.66666666666666, '%')\n",
      "Progress:  ('dummy encoding', 'LR', 73.33333333333333, '%')\n",
      "Progress:  ('dummy encoding', 'KNN', 80.0, '%')\n",
      "Progress:  ('dummy encoding', 'RF', 86.66666666666667, '%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  ('dummy encoding', 'XGBoost', 93.33333333333333, '%')\n",
      "Progress:  ('dummy encoding', 'SVM', 100.0, '%')\n",
      "            Encoding    Model  \\\n",
      "0   one-hot encoding       LR   \n",
      "1   one-hot encoding      KNN   \n",
      "2   one-hot encoding       RF   \n",
      "3   one-hot encoding  XGBoost   \n",
      "4   one-hot encoding      SVM   \n",
      "5     label encoding       LR   \n",
      "6     label encoding      KNN   \n",
      "7     label encoding       RF   \n",
      "8     label encoding  XGBoost   \n",
      "9     label encoding      SVM   \n",
      "10    dummy encoding       LR   \n",
      "11    dummy encoding      KNN   \n",
      "12    dummy encoding       RF   \n",
      "13    dummy encoding  XGBoost   \n",
      "14    dummy encoding      SVM   \n",
      "\n",
      "                                   Optimal parameters  \\\n",
      "0                                         {'C': 0.01}   \n",
      "1            {'n_neighbors': 9, 'weights': 'uniform'}   \n",
      "2   {'max_depth': 10, 'min_samples_leaf': 2, 'min_...   \n",
      "3   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
      "4                                          {'C': 0.1}   \n",
      "5                                            {'C': 1}   \n",
      "6            {'n_neighbors': 7, 'weights': 'uniform'}   \n",
      "7   {'max_depth': 10, 'min_samples_leaf': 4, 'min_...   \n",
      "8   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
      "9                                          {'C': 0.1}   \n",
      "10                                        {'C': 0.01}   \n",
      "11           {'n_neighbors': 7, 'weights': 'uniform'}   \n",
      "12  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...   \n",
      "13  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
      "14                                           {'C': 1}   \n",
      "\n",
      "    Accuracy score training  Accuracy score test  \\\n",
      "0                  0.572641             0.576299   \n",
      "1                  0.538141             0.532468   \n",
      "2                  0.535295             0.511364   \n",
      "3                  0.558436             0.574675   \n",
      "4                  0.568183             0.564935   \n",
      "5                  0.573451             0.569805   \n",
      "6                  0.544217             0.508117   \n",
      "7                  0.534889             0.516234   \n",
      "8                  0.559247             0.574675   \n",
      "9                  0.566957             0.551948   \n",
      "10                 0.572238             0.574675   \n",
      "11                 0.544217             0.508117   \n",
      "12                 0.535297             0.509740   \n",
      "13                 0.557625             0.574675   \n",
      "14                 0.568182             0.558442   \n",
      "\n",
      "                                 Precision score test  \\\n",
      "0   [0.5524475524475524, 0.25, 0.49056603773584906...   \n",
      "1   [0.49710982658959535, 0.0, 0.4301675977653631,...   \n",
      "2   [0.49635036496350365, 0.25, 0.4120603015075377...   \n",
      "3   [0.5746268656716418, 0.0, 0.4841628959276018, ...   \n",
      "4   [0.5486111111111112, 0.0, 0.45569620253164556,...   \n",
      "5   [0.5652173913043478, 0.25, 0.48292682926829267...   \n",
      "6   [0.5116279069767442, 0.1111111111111111, 0.417...   \n",
      "7   [0.49635036496350365, 0.25, 0.4215686274509804...   \n",
      "8   [0.5746268656716418, 0.0, 0.4841628959276018, ...   \n",
      "9   [0.5194805194805194, 0.0, 0.4595959595959596, ...   \n",
      "10  [0.5524475524475524, 0.25, 0.4880382775119617,...   \n",
      "11  [0.5116279069767442, 0.1111111111111111, 0.417...   \n",
      "12  [0.48091603053435117, 0.16666666666666666, 0.4...   \n",
      "13  [0.5746268656716418, 0.0, 0.4841628959276018, ...   \n",
      "14  [0.539568345323741, 0.0, 0.4585152838427948, 0...   \n",
      "\n",
      "                                         Recall_score          Training time  \\\n",
      "0   [0.572463768115942, 0.045454545454545456, 0.52... 0 days 00:00:10.309350   \n",
      "1   [0.6231884057971014, 0.0, 0.39086294416243655,... 0 days 00:00:01.235247   \n",
      "2   [0.4927536231884058, 0.045454545454545456, 0.4... 0 days 00:03:20.339631   \n",
      "3   [0.5579710144927537, 0.0, 0.5431472081218274, ... 0 days 00:00:43.098248   \n",
      "4   [0.572463768115942, 0.0, 0.5482233502538071, 0... 0 days 00:23:03.363070   \n",
      "5   [0.5652173913043478, 0.045454545454545456, 0.5... 0 days 00:00:14.831934   \n",
      "6   [0.4782608695652174, 0.045454545454545456, 0.4... 0 days 00:00:00.501910   \n",
      "7   [0.4927536231884058, 0.045454545454545456, 0.4... 0 days 00:03:11.464611   \n",
      "8   [0.5579710144927537, 0.0, 0.5431472081218274, ... 0 days 00:00:38.475854   \n",
      "9   [0.5797101449275363, 0.0, 0.4619289340101523, ... 0 days 00:21:24.297368   \n",
      "10  [0.572463768115942, 0.045454545454545456, 0.51... 0 days 00:00:14.027206   \n",
      "11  [0.4782608695652174, 0.045454545454545456, 0.4... 0 days 00:00:00.553015   \n",
      "12  [0.45652173913043476, 0.045454545454545456, 0.... 0 days 00:03:23.861522   \n",
      "13  [0.5579710144927537, 0.0, 0.5431472081218274, ... 0 days 00:00:48.924838   \n",
      "14  [0.5434782608695652, 0.0, 0.5329949238578681, ... 0 days 00:23:41.031745   \n",
      "\n",
      "          Prediction time  \n",
      "0  0 days 00:00:00.008740  \n",
      "1  0 days 00:00:00.140341  \n",
      "2  0 days 00:00:00.096432  \n",
      "3  0 days 00:00:00.016675  \n",
      "4  0 days 00:00:00.105250  \n",
      "5  0 days 00:00:00.020306  \n",
      "6  0 days 00:00:00.043113  \n",
      "7  0 days 00:00:00.093694  \n",
      "8  0 days 00:00:00.010025  \n",
      "9  0 days 00:00:00.080035  \n",
      "10 0 days 00:00:00.015775  \n",
      "11 0 days 00:00:00.043315  \n",
      "12 0 days 00:00:00.060097  \n",
      "13 0 days 00:00:00.010035  \n",
      "14 0 days 00:00:00.058887  \n",
      "Note: The training time is the training time for all models created in gridsearch framework of the given combination of encoder and model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomko\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "encoding_list = [\"one-hot encoding\", \"label encoding\", \"dummy encoding\"]\n",
    "model_list = [\"LR\", \"KNN\", \"RF\", \"XGBoost\", \"SVM\"]\n",
    "counter = 0\n",
    "        \n",
    "results_table = []\n",
    "\n",
    "\n",
    "for i in encoding_list:\n",
    "    url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise-3%20mode%20choice%20model/modeChoiceData.csv'\n",
    "    data = pd.read_csv(url)\n",
    "    if i == \"one-hot encoding\":\n",
    "        df = pd.get_dummies(data, columns=['service_air', 'service_rail'])\n",
    "    elif i == \"label encoding\":\n",
    "        encoder = LabelEncoder()\n",
    "        df=data.copy()\n",
    "        df['service_air'] = encoder.fit_transform(df['service_air'])\n",
    "        df['service_rail'] = encoder.fit_transform(df['service_rail'])\n",
    "    elif i == \"dummy encoding\":\n",
    "        df=data.copy()\n",
    "        dummy_df = pd.get_dummies(df[['service_air', 'service_rail']], drop_first=True)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        df = df.drop(['service_air', 'service_rail'],axis=1)\n",
    "    else:\n",
    "        print(\"Error: Encoding method not found!\", i)\n",
    "    \n",
    "    x = df.drop(['choice','ID',], axis=1)\n",
    "    y = df['choice']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=0)\n",
    "    \n",
    "    for j in model_list:\n",
    "        results_list = []\n",
    "        start_training_time = dt.datetime.now()\n",
    "        if j == \"LR\":\n",
    "            params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "            model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "        elif j == \"KNN\":\n",
    "            params = {'n_neighbors': [3, 5, 7, 9], \n",
    "                      'weights': ['uniform', 'distance']}\n",
    "            model=KNeighborsClassifier()\n",
    "        elif j == \"RF\":\n",
    "            params = {'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [None, 10, 20, 30],\n",
    "                      'min_samples_split': [2, 5, 10],\n",
    "                      'min_samples_leaf': [1, 2, 4]}\n",
    "            model = RandomForestClassifier(random_state=0)\n",
    "        elif j == \"XGBoost\":\n",
    "            params = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "                      'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [3, 4, 5]}\n",
    "            map = {'air': 0, 'bus': 1, 'car': 2,'rail':3}\n",
    "            y_train = y_train.map(map)\n",
    "            y_test = y_test.map(map)\n",
    "            model =  XGBClassifier()\n",
    "        elif j == \"SVM\":\n",
    "            params = {'C': [0.1, 1, 10]}\n",
    "            model= SVC(kernel=\"linear\") \n",
    "        else:\n",
    "            print(\"Error: Model not found!\", j)\n",
    "            \n",
    "        # Initialize and fit a GridSearchCV object to perform hyperparameter tuning:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        \n",
    "        #Find best parameters and corresponding accuracy score:\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        end_training_time = dt.datetime.now()\n",
    "        training_time = end_training_time - start_training_time\n",
    "        \n",
    "        start_predicting_time = dt.datetime.now()\n",
    "        #Run the model-vectorizer combination on the test set for the best parameter combination\n",
    "        model = grid_search.best_estimator_\n",
    "        \n",
    "        # Measures for test data\n",
    "        accuracy_score_variable = accuracy_score(y_test,model.predict(x_test))\n",
    "        precision_score_variable = precision_score(y_test,model.predict(x_test),average=None)\n",
    "        recall_score_variable = recall_score(y_test,model.predict(x_test),average=None)\n",
    "        \n",
    "        end_predicting_time = dt.datetime.now()\n",
    "        predicting_time = end_predicting_time - start_predicting_time\n",
    "\n",
    "                            \n",
    "        results_list.extend([i, j, best_params, best_score, accuracy_score_variable, precision_score_variable, recall_score_variable, training_time, predicting_time])\n",
    "        results_table.append(results_list)        \n",
    "        \n",
    "        counter = counter + 1\n",
    "        print(\"Progress: \", (i, j, (counter/(len(encoding_list)*len(model_list)))*100, \"%\"))\n",
    "        \n",
    "\n",
    "df_results = pd.DataFrame(results_table, columns = [\"Encoding\", \"Model\", \"Optimal parameters\", \"Accuracy score training\", \n",
    "                                     \"Accuracy score test\", \"Precision score test\", \n",
    "                                     \"Recall_score\", \"Training time\", \"Prediction time\"])\n",
    "        \n",
    "print(df_results)\n",
    "print(\"Note: The training time is the training time for all models created in gridsearch framework of the given combination of encoder and model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21447643",
   "metadata": {},
   "source": [
    "### Train and test all combinations of encoders and models with extra column for total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b06e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  time_car  cost_car  time_bus  cost_bus  access_bus  time_air  cost_air  \\\n",
      "0   1       275        50       330        35          20        80        65   \n",
      "1   2       275        45       330        15           5        70       110   \n",
      "2   3       275        45       390        15          25        70        80   \n",
      "3   4       300        45       300        15          10        60       110   \n",
      "4   5       390        35       390        35          10        60        95   \n",
      "\n",
      "   access_air service_air  time_rail  cost_rail  access_rail service_rail  \\\n",
      "0          55        food        120         45            5    no-frills   \n",
      "1          40        wifi        170         55           25         food   \n",
      "2          55   no-frills        155         35            5    no-frills   \n",
      "3          40        wifi        155         65           20    no-frills   \n",
      "4          45        wifi        155         65           15         food   \n",
      "\n",
      "  choice  total_time_bus  total_time_air  total_time_rail  \n",
      "0    air             350             135              125  \n",
      "1   rail             335             110              195  \n",
      "2   rail             415             125              160  \n",
      "3   rail             310             100              175  \n",
      "4   rail             400             105              170  \n"
     ]
    }
   ],
   "source": [
    "encoding_list = [\"one-hot encoding\", \"label encoding\", \"dummy encoding\"]\n",
    "model_list = [\"LR\", \"KNN\", \"RF\", \"XGBoost\", \"SVM\"]\n",
    "counter = 0\n",
    "        \n",
    "results_table = []\n",
    "\n",
    "for i in encoding_list:\n",
    "    url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise-3%20mode%20choice%20model/modeChoiceData.csv'\n",
    "    data = pd.read_csv(url)\n",
    "    data[\"total_time_bus\"] = data[\"time_bus\"] + data[\"access_bus\"]\n",
    "    data[\"total_time_air\"] = data[\"time_air\"] + data[\"access_air\"]\n",
    "    data[\"total_time_rail\"] = data[\"time_rail\"] + data[\"access_rail\"]\n",
    "\n",
    "    if i == \"one-hot encoding\":\n",
    "        df = pd.get_dummies(data, columns=['service_air', 'service_rail'])\n",
    "    elif i == \"label encoding\":\n",
    "        encoder = LabelEncoder()\n",
    "        df=data.copy()\n",
    "        df['service_air'] = encoder.fit_transform(df['service_air'])\n",
    "        df['service_rail'] = encoder.fit_transform(df['service_rail'])\n",
    "    elif i == \"dummy encoding\":\n",
    "        df=data.copy()\n",
    "        dummy_df = pd.get_dummies(df[['service_air', 'service_rail']], drop_first=True)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        df = df.drop(['service_air', 'service_rail'],axis=1)\n",
    "    else:\n",
    "        print(\"Error: Encoding method not found!\", i)\n",
    "    \n",
    "    x = df.drop(['choice','ID',], axis=1)\n",
    "    y = df['choice']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=0)\n",
    "    \n",
    "    for j in model_list:\n",
    "        results_list = []\n",
    "        start_training_time = dt.datetime.now()\n",
    "        if j == \"LR\":\n",
    "            params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "            model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "        elif j == \"KNN\":\n",
    "            params = {'n_neighbors': [3, 5, 7, 9], \n",
    "                      'weights': ['uniform', 'distance']}\n",
    "            model=KNeighborsClassifier()\n",
    "        elif j == \"RF\":\n",
    "            params = {'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [None, 10, 20, 30],\n",
    "                      'min_samples_split': [2, 5, 10],\n",
    "                      'min_samples_leaf': [1, 2, 4]}\n",
    "            model = RandomForestClassifier(random_state=0)\n",
    "        elif j == \"XGBoost\":\n",
    "            params = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "                      'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [3, 4, 5]}\n",
    "            map = {'air': 0, 'bus': 1, 'car': 2,'rail':3}\n",
    "            y_train = y_train.map(map)\n",
    "            y_test = y_test.map(map)\n",
    "            model =  XGBClassifier()\n",
    "        elif j == \"SVM\":\n",
    "            params = {'C': [0.1, 1, 10]}\n",
    "            model= SVC(kernel=\"linear\") \n",
    "        else:\n",
    "            print(\"Error: Model not found!\", j)\n",
    "            \n",
    "        # Initialize and fit a GridSearchCV object to perform hyperparameter tuning:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        \n",
    "        #Find best parameters and corresponding accuracy score:\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        end_training_time = dt.datetime.now()\n",
    "        training_time = end_training_time - start_training_time\n",
    "        \n",
    "        start_predicting_time = dt.datetime.now()\n",
    "        #Run the model-vectorizer combination on the test set for the best parameter combination\n",
    "        model = grid_search.best_estimator_\n",
    "        \n",
    "        # Measures for test data\n",
    "        accuracy_score_variable = accuracy_score(y_test,model.predict(x_test))\n",
    "        precision_score_variable = precision_score(y_test,model.predict(x_test),average=None)\n",
    "        recall_score_variable = recall_score(y_test,model.predict(x_test),average=None)\n",
    "        \n",
    "        end_predicting_time = dt.datetime.now()\n",
    "        predicting_time = end_predicting_time - start_predicting_time\n",
    "\n",
    "                            \n",
    "        results_list.extend([i, j, best_params, best_score, accuracy_score_variable, precision_score_variable, recall_score_variable, training_time, predicting_time])\n",
    "        results_table.append(results_list)        \n",
    "        \n",
    "        counter = counter + 1\n",
    "        print(\"Progress: \", (i, j, (counter/(len(encoding_list)*len(model_list)))*100, \"%\"))\n",
    "        \n",
    "\n",
    "df_results2 = pd.DataFrame(results_table, columns = [\"Encoding\", \"Model\", \"Optimal parameters\", \"Accuracy score training\", \n",
    "                                     \"Accuracy score test\", \"Precision score test\", \n",
    "                                     \"Recall_score\", \"Training time\", \"Prediction time\"])\n",
    "        \n",
    "print(df_results2)\n",
    "print(\"Note: The training time is the training time for all models created in gridsearch framework of the given combination of encoder and model.\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf611ee",
   "metadata": {},
   "source": [
    "### Train and test all combinations of encoders and models with extra columns for total time and cost per time unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_list = [\"one-hot encoding\", \"label encoding\", \"dummy encoding\"]\n",
    "model_list = [\"LR\", \"KNN\", \"RF\", \"XGBoost\", \"SVM\"]\n",
    "counter = 0\n",
    "        \n",
    "results_table = []\n",
    "\n",
    "for i in encoding_list:\n",
    "    url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise-3%20mode%20choice%20model/modeChoiceData.csv'\n",
    "    data = pd.read_csv(url)\n",
    "    data[\"total_time_bus\"] = data[\"time_bus\"] + data[\"access_bus\"]\n",
    "    data[\"total_time_air\"] = data[\"time_air\"] + data[\"access_air\"]\n",
    "    data[\"total_time_rail\"] = data[\"time_rail\"] + data[\"access_rail\"]\n",
    "    data[\"cost_time_car\"] = data[\"time_car\"]/data[\"cost_car\"]\n",
    "    data[\"cost_time_bus\"] = data[\"total_time_bus\"]/data[\"cost_bus\"]\n",
    "    data[\"cost_time_air\"] = data[\"total_time_air\"]/data[\"cost_air\"]\n",
    "    data[\"cost_time_rail\"] = data[\"total_time_rail\"]/data[\"cost_rail\"]\n",
    "\n",
    "    if i == \"one-hot encoding\":\n",
    "        df = pd.get_dummies(data, columns=['service_air', 'service_rail'])\n",
    "    elif i == \"label encoding\":\n",
    "        encoder = LabelEncoder()\n",
    "        df=data.copy()\n",
    "        df['service_air'] = encoder.fit_transform(df['service_air'])\n",
    "        df['service_rail'] = encoder.fit_transform(df['service_rail'])\n",
    "    elif i == \"dummy encoding\":\n",
    "        df=data.copy()\n",
    "        dummy_df = pd.get_dummies(df[['service_air', 'service_rail']], drop_first=True)\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        df = df.drop(['service_air', 'service_rail'],axis=1)\n",
    "    else:\n",
    "        print(\"Error: Encoding method not found!\", i)\n",
    "    \n",
    "    x = df.drop(['choice','ID',], axis=1)\n",
    "    y = df['choice']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=0)\n",
    "    \n",
    "    for j in model_list:\n",
    "        results_list = []\n",
    "        start_training_time = dt.datetime.now()\n",
    "        if j == \"LR\":\n",
    "            params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "            model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "        elif j == \"KNN\":\n",
    "            params = {'n_neighbors': [3, 5, 7, 9], \n",
    "                      'weights': ['uniform', 'distance']}\n",
    "            model=KNeighborsClassifier()\n",
    "        elif j == \"RF\":\n",
    "            params = {'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [None, 10, 20, 30],\n",
    "                      'min_samples_split': [2, 5, 10],\n",
    "                      'min_samples_leaf': [1, 2, 4]}\n",
    "            model = RandomForestClassifier(random_state=0)\n",
    "        elif j == \"XGBoost\":\n",
    "            params = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "                      'n_estimators': [100, 200, 300],\n",
    "                      'max_depth': [3, 4, 5]}\n",
    "            map = {'air': 0, 'bus': 1, 'car': 2,'rail':3}\n",
    "            y_train = y_train.map(map)\n",
    "            y_test = y_test.map(map)\n",
    "            model =  XGBClassifier()\n",
    "        elif j == \"SVM\":\n",
    "            params = {'C': [0.1, 1, 10]}\n",
    "            model= SVC(kernel=\"linear\") \n",
    "        else:\n",
    "            print(\"Error: Model not found!\", j)\n",
    "            \n",
    "        # Initialize and fit a GridSearchCV object to perform hyperparameter tuning:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        \n",
    "        #Find best parameters and corresponding accuracy score:\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        end_training_time = dt.datetime.now()\n",
    "        training_time = end_training_time - start_training_time\n",
    "        \n",
    "        start_predicting_time = dt.datetime.now()\n",
    "        #Run the model-vectorizer combination on the test set for the best parameter combination\n",
    "        model = grid_search.best_estimator_\n",
    "        \n",
    "        # Measures for test data\n",
    "        accuracy_score_variable = accuracy_score(y_test,model.predict(x_test))\n",
    "        precision_score_variable = precision_score(y_test,model.predict(x_test),average=None)\n",
    "        recall_score_variable = recall_score(y_test,model.predict(x_test),average=None)\n",
    "        \n",
    "        end_predicting_time = dt.datetime.now()\n",
    "        predicting_time = end_predicting_time - start_predicting_time\n",
    "\n",
    "                            \n",
    "        results_list.extend([i, j, best_params, best_score, accuracy_score_variable, precision_score_variable, recall_score_variable, training_time, predicting_time])\n",
    "        results_table.append(results_list)        \n",
    "        \n",
    "        counter = counter + 1\n",
    "        print(\"Progress: \", (i, j, (counter/(len(encoding_list)*len(model_list)))*100, \"%\"))\n",
    "        \n",
    "\n",
    "df_results2 = pd.DataFrame(results_table, columns = [\"Encoding\", \"Model\", \"Optimal parameters\", \"Accuracy score training\", \n",
    "                                     \"Accuracy score test\", \"Precision score test\", \n",
    "                                     \"Recall_score\", \"Training time\", \"Prediction time\"])\n",
    "        \n",
    "print(df_results2)\n",
    "print(\"Note: The training time is the training time for all models created in gridsearch framework of the given combination of encoder and model.\")\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
